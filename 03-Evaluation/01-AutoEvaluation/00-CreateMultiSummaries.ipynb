{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf4a711e",
   "metadata": {},
   "source": [
    "# Gold-Standard Event Summaries for CrisisFACTS\n",
    "\n",
    "__Author__: Cody Buntain (cbuntain@umd.edu)\n",
    "\n",
    "## Description\n",
    "\n",
    "For automated evaluation in CrisisFACTS, we compare participant-system summaries to three additional sources of event summaries:\n",
    "\n",
    "1. Wikipedia - A simple summary of each event, though we expect these summaries are not massively useful for situational awareness, attention support, or decision making.\n",
    "\n",
    "2. ICS 209 Archive - A dataset of real daily hazard reports, gathered from Lise St. Denis. This data comes from a pre-release version of their updated NIMS database.\n",
    "\n",
    "    - St. Denis, L., Short, K., McConnell, K., Cook, M., Mietkiewicz, N., Buckland, M. & Balch, J. All-hazards dataset mined from the US National Incident Management System 1999â€“2012. Sci Data (2022).\n",
    " \n",
    "    - St. Denis, L., Short, K., McConnell, K., Cook, M., Mietkiewicz, N., Buckland, M. & Balch, J. All-hazards dataset mined from the US National Incident Management System 1999-2020. figshare. https://doi.org/10.6084/m9.figshare.19858927 (2022).\n",
    "    \n",
    "3. NIST Assessor Summaries - A dataset of event summaries generated by NIST assessors, where CrisisFACTS coordinators asked NIST assessors to identify and timestamp important facts from each event.\n",
    "\n",
    "## Notes\n",
    "\n",
    "You _cannot_ run this code to generate the ICS 209 summaries yet, as the underlying dataset has not been publicly released. As soon as it is available, we will update this code appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b81a284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import requests\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b527353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a36ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the wikipedia package, so we can get Wikipedia summaries\n",
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c7d07d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758b1799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c22767d1",
   "metadata": {},
   "source": [
    "## Pre-built data\n",
    "\n",
    "We have selected topics for CrisisFACTS 2022 and matched them to the ICS 209 dataset from L. St. Denis et al., which we read in here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bf9c52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = None\n",
    "with open(\"CrisisFACTs-2022.topics.json\", \"r\") as in_file:\n",
    "    topics = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fea0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_to_ics = None\n",
    "with open(\"CrisisFACTs-2022.topics.to.ic209.json\", \"r\") as in_file:\n",
    "    topic_to_ics = json.load(in_file)\n",
    "topic_to_ics_map = {row[\"eventID\"]:row[\"icsID\"] for row in topic_to_ics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fcb02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the ICS 209 report ID set (can be multiple) for each event\n",
    "\n",
    "for topic in topics:\n",
    "    e_id = topic[\"eventID\"]\n",
    "    topic[\"icsID\"] = topic_to_ics_map[e_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc25353",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b941c0c",
   "metadata": {},
   "source": [
    "## Get Wikipedia Summaries\n",
    "\n",
    "For each topic, we have a Wikipedia URL already provided. Use that page to get Wikipedia's own summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27c1c008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Lilac_Fire\n",
      "\t Lilac_Fire\n",
      "https://en.wikipedia.org/wiki/Cranston_Fire\n",
      "\t Cranston_Fire\n",
      "https://en.wikipedia.org/wiki/Holy_Fire_(2018)\n",
      "\t Holy_Fire_(2018)\n",
      "https://en.wikipedia.org/wiki/Hurricane_Florence\n",
      "\t Hurricane_Florence\n",
      "https://en.wikipedia.org/wiki/2018_Maryland_flood\n",
      "\t 2018_Maryland_flood\n",
      "https://en.wikipedia.org/wiki/Saddleridge_Fire\n",
      "\t Saddleridge_Fire\n",
      "https://en.wikipedia.org/wiki/Hurricane_Laura\n",
      "\t Hurricane_Laura\n",
      "https://en.wikipedia.org/wiki/Hurricane_Sally\n",
      "\t Hurricane_Sally\n"
     ]
    }
   ],
   "source": [
    "# Every topic has a URL to a Wiki page.\n",
    "for topic in topics:\n",
    "    print(topic[\"url\"])\n",
    "    page_title = topic[\"url\"].rpartition(\"/\")[-1]\n",
    "    \n",
    "    print(\"\\t\", page_title)\n",
    "    page = wikipedia.page(title=page_title, auto_suggest=False)\n",
    "    \n",
    "    topic[\"wiki.content\"] = page.content\n",
    "    topic[\"wiki.summary\"] = page.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fc010e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hurricane Sally was a destructive and slow-moving Atlantic hurricane, which was the first hurricane to make landfall in the U.S. state of Alabama since Ivan in 2004, coincidentally on the same date in the same place. The eighteenth named storm, and seventh hurricane of the extremely active 2020 Atlantic hurricane season, Sally developed from an area of disturbed weather which was first monitored over the Bahamas on September 10. The system grew a broad area of low-pressure on September 11, and was designated as a tropical depression late that day. Early the next day, the depression made landfall at Key Biscayne, and subsequently strengthened into Tropical Storm Sally that afternoon. Moderate northwesterly shear prevented significant intensification for the first two days, but convection continued to grow towards the center and Sally slowly intensified. On September 14, a center reformation into the center of the convection occurred, and data from a hurricane hunter reconnaissance aircraft showed that Sally rapidly intensified into a strong Category 1 hurricane. However, an increase in wind shear and upwelling of colder waters halted the intensification and Sally weakened slightly on September 15 before turning slowly northeastward. Despite this increase in wind shear, it unexpectedly re-intensified, reaching Category 2 status early on September 16, before making landfall at peak intensity at 09:45 UTC on September 16, near Gulf Shores, Alabama, with maximum sustained winds of 110 mph (175 km/h) and a minimum central pressure of 965 millibars (28.5 inHg). The storm rapidly weakened after landfall, before transitioning into an extratropical low at 12:00 UTC the next day. Sally's remnants lasted for another day as they moved off the coast of the Southeastern United States, before being absorbed into another extratropical storm on September 18.\\nNumerous watches and warnings were issued in anticipation of the imminent approach of Sally and several coastline counties and parishes on the Gulf Coast were evacuated. In South Florida, heavy rain led to localized flash flooding while the rest of peninsula saw continuous shower and thunderstorm activity due to asymmetric structure of Sally. The area between Mobile, Alabama, and Pensacola, Florida, took the brunt of the storm with widespread wind damage, storm surge flooding, and over 20 inches (510 mm) of rainfall. Numerous tornadoes also occurred as well. Damage is estimated at $7.3 billion (2020 USD). Despite the destruction caused by the storm, the name Sally was not retired during the following year making Sally the costliest tropical cyclone in the North Atlantic on record that did not have its name retired.\\n\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example summary from Hurricane Sally\n",
    "page.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8b6a02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8dbaa193",
   "metadata": {},
   "source": [
    "## Extract Summaries from ICS 209 Data\n",
    "\n",
    "Much of the ICS 209 data isn't in a reasonable format for summaries, and many fields aren't directly useful. Here, we read in the 1999-2020 dataset and convert a subset of these fields to sentences for summarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae866cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"ics-209-plus-2.0-pre-release-v1/ics209-plus_sitreps_1999to2020.csv\", \n",
    "    low_memory=False, \n",
    "    index_col=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd65e03",
   "metadata": {},
   "source": [
    "## NOTE: THE ABOVE CODE WILL CURRENTLY FAIL\n",
    "\n",
    "We cannot release the ICS 209 dataset yet, as the underlying dataset is still in pre-release. Once St. Denis et al. publicly release the dataset, we will update this code accordingly.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf505db",
   "metadata": {},
   "source": [
    "Each key in the `narr_prompts` map is a field in the ICS 209 entry, and each value in `narr_prompts` provides a sentence-based summary of that field. Some fields include only numeric data, e.g., total evacuations, so we embed that number in a sentence using the fields below. Other fields, such as `INCIDENT_DESCRIPTION`, is a narrative field (i.e., text entry), and we use that field directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5341c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "narr_prompts = {\n",
    "    \"CAUSE\":    \"The cause of the incident is _PLACEHOLDER_.\",\n",
    "    \"TOTAL_EVACUATIONS\":    \"_PLACEHOLDER_ evacuations to date.\",\n",
    "    \"TOTAL_P_FATALITIES\":    \"_PLACEHOLDER_ fatalities to date.\",\n",
    "    \"TOTAL_P_INJURIES\":    \"_PLACEHOLDER_ injuries to date.\",\n",
    "    \"TOTAL_PERSONNEL\":    \"_PLACEHOLDER_ personnel deployed.\",\n",
    "    \"TOTAL_R_FATALITIES\":    \"_PLACEHOLDER_ responder fatalities.\",\n",
    "    \"TOTAL_R_INJURIES\":    \"_PLACEHOLDER_ repsonder injuries.\",\n",
    "    \"ACRES\":    \"_PLACEHOLDER_ acres have been affected.\",\n",
    "    \"EDAMAGE\":    \"Estimated damage at _PLACEHOLDER_.\",\n",
    "    \"FATALITIES\":    \"_PLACEHOLDER_ fatalities.\",\n",
    "    \"INJURIES\":    \"_PLACEHOLDER_ injuries this period.\",\n",
    "    \"INJURIES_TO_DATE\":    \"_PLACEHOLDER_ injuries to date.\",\n",
    "    \"STR_DAMAGED\":    \"_PLACEHOLDER_ structures damaged.\",\n",
    "    \"STR_DAMAGED_COMM\":    \"_PLACEHOLDER_ commercial structures damaged.\",\n",
    "    \"STR_DAMAGED_RES\":    \"_PLACEHOLDER_ residential structures damaged.\",\n",
    "    \"STR_DESTROYED\":    \"_PLACEHOLDER_ structures destroyed.\",\n",
    "    \"STR_DESTROYED_COMM\":    \"_PLACEHOLDER_ commercial structures destroyed.\",\n",
    "    \"STR_DESTROYED_RES\":    \"_PLACEHOLDER_ residential structures destroyed.\",\n",
    "    \"STR_THREATENED\":    \"_PLACEHOLDER_ structures currently threatened.\",\n",
    "    \"STR_THREATENED_COMM\":    \"_PLACEHOLDER_ commercial structures currently threatened.\",\n",
    "    \"STR_THREATENED_RES\":    \"_PLACEHOLDER_ residential structures currently threatened.\",\n",
    "    \"UNIT_OR_OTHER_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"WEATHER_CONCERNS_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"COMPLEXITY_LEVEL_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"CRIT_RES_NEEDS_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"CURRENT_THREAT_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"HAZARDS_MATLS_INVOLVMENT_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"INCIDENT_COMMANDERS_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"INCIDENT_DESCRIPTION\":    \"_PLACEHOLDER_\",\n",
    "    \"INCIDENT_JURISDICTION\":    \"_PLACEHOLDER_\",\n",
    "    \"INCTYP_DESC\":    \"_PLACEHOLDER_\",\n",
    "    \"LIFE_SAFETY_HEALTH_STATUS_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"MAJOR_PROBLEMS\":    \"_PLACEHOLDER_\",\n",
    "    \"OBS_FIRE_BEHAVE\":    \"_PLACEHOLDER_\",\n",
    "    \"PLANNED_ACTIONS\":    \"_PLACEHOLDER_\",\n",
    "    \"POO_SHORT_LOCATION_DESC\":    \"_PLACEHOLDER_\",\n",
    "    \"PROJECTED_ACTIVITY_NARR\":    \"_PLACEHOLDER_\",\n",
    "    \"REMARKS\":    \"_PLACEHOLDER_\",\n",
    "    \"RES_BENEFITS\":    \"_PLACEHOLDER_\",\n",
    "    \"RISK_ASSESSMENT\":    \"_PLACEHOLDER_\",\n",
    "    \"SIGNIF_EVENTS_SUMMARY\":    \"_PLACEHOLDER_\",\n",
    "    \"STATUS\":    \"_PLACEHOLDER_\",\n",
    "    \"STRATEGIC_NARR\":    \"_PLACEHOLDER_\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c03975",
   "metadata": {},
   "source": [
    "For every topic, pull the set of ICS 209 IDs that map in to the ICS data frame we read above.\n",
    "\n",
    "Then we pull out each numeric and narrative field from above and add them to our running set of summaries. We use a set here to ensure we have unique sentences in the summary field, which is useful since some of the 209 reports duplicate content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf3579fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lilac Wildfire 2017\n",
      "\t Relevant Rows: 18\n",
      "Cranston Wildfire 2018\n",
      "\t Relevant Rows: 23\n",
      "Holy Wildfire 2018\n",
      "\t Relevant Rows: 42\n",
      "Hurricane Florence 2018\n",
      "\t Relevant Rows: 47\n",
      "2018 Maryland Flood\n",
      "\t Relevant Rows: 0\n",
      "\t No rows...\n",
      "Saddleridge Wildfire 2019\n",
      "\t Relevant Rows: 27\n",
      "Hurricane Laura 2020\n",
      "\t Relevant Rows: 10\n",
      "Hurricane Sally 2020\n",
      "\t Relevant Rows: 3\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic[\"title\"])\n",
    "    ics_id = topic[\"icsID\"]\n",
    "    indices = []\n",
    "    \n",
    "    # Gereate the set of Incident IDs, which as stored as CSV\n",
    "    if \",\" in ics_id:\n",
    "        multi_ics_ids = ics_id.split(\",\")\n",
    "        \n",
    "        for sub_ics_id in multi_ics_ids:\n",
    "            relevant_ics_df = df[df[\"INCIDENT_ID\"] == sub_ics_id.strip()]\n",
    "            indices.extend(relevant_ics_df.index)\n",
    "    else:\n",
    "        relevant_ics_df = df[df[\"INCIDENT_ID\"] == ics_id]\n",
    "        indices.extend(relevant_ics_df.index)\n",
    "\n",
    "        \n",
    "    print(\"\\t\", \"Relevant Rows:\", len(indices))\n",
    "    \n",
    "    # Some events don't have a corresponding ICS 209 field\n",
    "    #. such as the Maryland Floods, which we included for\n",
    "    #. geographic relevance to NIST assessors\n",
    "    if len(indices) == 0:\n",
    "        print(\"\\t\", \"No rows...\")\n",
    "        continue\n",
    "        \n",
    "    relevant_ics_df = df.loc[indices]\n",
    "    \n",
    "    summaries = set()\n",
    "    for idx,row in relevant_ics_df.iterrows():\n",
    "        lrow = row.dropna()\n",
    "        \n",
    "        for field,prompt in narr_prompts.items():\n",
    "            \n",
    "            if field not in lrow:\n",
    "                continue\n",
    "            \n",
    "            if row[field] == 0:\n",
    "                continue\n",
    "                \n",
    "            new_str = prompt.replace(\"_PLACEHOLDER_\", str(row[field]))\n",
    "            summaries.add(new_str)\n",
    "            \n",
    "        # Add summaries for binary flag fields\n",
    "        if row[\"ROAD_CLOSURE_FLAG\"]:\n",
    "            summaries.add(\"Roads closed.\")\n",
    "        if row[\"EVACUATION_IN_PROGRESS\"]:\n",
    "            summaries.add(\"Evacuations underway.\")\n",
    "\n",
    "\n",
    "    topic[\"ics.summary\"] = \" \".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089f5992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb85261b",
   "metadata": {},
   "source": [
    "## Extract Summaries from NIST Assessors\n",
    "\n",
    "We also have facts from NIST assessors, and we use those to create summaries as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c49e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"CrisisFACTs-2022.facts.json\", \"r\") as in_file:\n",
    "    facts = json.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48882535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-001 Lilac Wildfire 2017\n",
      "\t CrisisFACTS-001-r3 267\n",
      "\t CrisisFACTS-001-r4 75\n",
      "\t CrisisFACTS-001-r5 14\n",
      "\t CrisisFACTS-001-r6 29\n",
      "\t CrisisFACTS-001-r7 19\n",
      "\t CrisisFACTS-001-r8 5\n",
      "\t CrisisFACTS-001-r9 3\n",
      "\t CrisisFACTS-001-r10 3\n",
      "\t CrisisFACTS-001-r11 2\n",
      "CrisisFACTS-002 Cranston Wildfire 2018\n",
      "\t CrisisFACTS-002-r1 27\n",
      "\t CrisisFACTS-002-r2 10\n",
      "\t CrisisFACTS-002-r3 4\n",
      "\t CrisisFACTS-002-r4 13\n",
      "\t CrisisFACTS-002-r5 7\n",
      "\t CrisisFACTS-002-r6 1\n",
      "CrisisFACTS-003 Holy Wildfire 2018\n",
      "\t CrisisFACTS-003-r5 37\n",
      "\t CrisisFACTS-003-r6 42\n",
      "\t CrisisFACTS-003-r7 39\n",
      "\t CrisisFACTS-003-r8 37\n",
      "\t CrisisFACTS-003-r9 9\n",
      "\t CrisisFACTS-003-r10 17\n",
      "\t CrisisFACTS-003-r11 4\n",
      "CrisisFACTS-004 Hurricane Florence 2018\n",
      "\t CrisisFACTS-004-r8 5\n",
      "\t CrisisFACTS-004-r9 5\n",
      "\t CrisisFACTS-004-r10 2\n",
      "\t CrisisFACTS-004-r11 4\n",
      "\t CrisisFACTS-004-r12 8\n",
      "\t CrisisFACTS-004-r13 15\n",
      "\t CrisisFACTS-004-r14 55\n",
      "\t CrisisFACTS-004-r15 26\n",
      "\t CrisisFACTS-004-r16 14\n",
      "\t CrisisFACTS-004-r17 37\n",
      "\t CrisisFACTS-004-r18 46\n",
      "\t CrisisFACTS-004-r19 3\n",
      "\t CrisisFACTS-004-r20 6\n",
      "\t CrisisFACTS-004-r21 3\n",
      "\t CrisisFACTS-004-r22 3\n",
      "CrisisFACTS-005 2018 Maryland Flood\n",
      "\t CrisisFACTS-005-r3 55\n",
      "\t CrisisFACTS-005-r4 15\n",
      "\t CrisisFACTS-005-r5 3\n",
      "\t CrisisFACTS-005-r6 1\n",
      "CrisisFACTS-006 Saddleridge Wildfire 2019\n",
      "\t CrisisFACTS-006-r4 6\n",
      "\t CrisisFACTS-006-r5 116\n",
      "\t CrisisFACTS-006-r6 12\n",
      "\t CrisisFACTS-006-r7 3\n",
      "CrisisFACTS-007 Hurricane Laura 2020\n",
      "\t CrisisFACTS-007-r13 188\n",
      "\t CrisisFACTS-007-r14 11\n",
      "CrisisFACTS-008 Hurricane Sally 2020\n",
      "\t CrisisFACTS-008-r3 2\n",
      "\t CrisisFACTS-008-r4 12\n",
      "\t CrisisFACTS-008-r5 14\n",
      "\t CrisisFACTS-008-r6 26\n",
      "\t CrisisFACTS-008-r7 30\n",
      "\t CrisisFACTS-008-r8 72\n",
      "\t CrisisFACTS-008-r9 19\n",
      "\t CrisisFACTS-008-r10 1\n"
     ]
    }
   ],
   "source": [
    "collection_files = []\n",
    "collection_dfs = []\n",
    "\n",
    "total_fact_count = 0\n",
    "for event in facts:\n",
    "    event_name = event[\"event\"]\n",
    "    event_id = event[\"eventID\"]\n",
    "    event_requests = event[\"summaryRequests\"]\n",
    "    event_factsXrequests = event[\"factsByRequest\"]\n",
    "\n",
    "    print(event_id, event_name)\n",
    "    for event_request in event_requests:\n",
    "        req_id = event_request[\"requestID\"]        \n",
    "        this_req_facts = event_factsXrequests[req_id]\n",
    "        fact_count = len(this_req_facts)\n",
    "        fact_collection = [fact[\"fact\"] for fact in this_req_facts]\n",
    "        \n",
    "        this_event_req_df = pd.DataFrame(fact_collection, columns=[\"fact\"])\n",
    "        this_event_req_df[\"title\"] = [\"%s-%d\" % (req_id,i) for i in this_event_req_df.index]\n",
    "        \n",
    "        print(\"\\t\", req_id, fact_count)\n",
    "        \n",
    "        collection_dfs.append(this_event_req_df)\n",
    "        total_fact_count += fact_count\n",
    "        \n",
    "all_nist_facts_df = pd.concat(collection_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4133a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f2fb039b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CrisisFACTS-001\n",
      "\t 417\n",
      "CrisisFACTS-002\n",
      "\t 62\n",
      "CrisisFACTS-003\n",
      "\t 185\n",
      "CrisisFACTS-004\n",
      "\t 232\n",
      "CrisisFACTS-005\n",
      "\t 74\n",
      "CrisisFACTS-006\n",
      "\t 137\n",
      "CrisisFACTS-007\n",
      "\t 199\n",
      "CrisisFACTS-008\n",
      "\t 176\n"
     ]
    }
   ],
   "source": [
    "for topic in topics:\n",
    "    print(topic[\"eventID\"])\n",
    "    \n",
    "    this_topic_nist_facts = all_nist_facts_df[all_nist_facts_df[\"title\"].str.startswith(topic[\"eventID\"])]\n",
    "    print(\"\\t\", this_topic_nist_facts.shape[0])\n",
    "\n",
    "    topic[\"nist.fact_depth\"] = this_topic_nist_facts.shape[0]\n",
    "    topic[\"nist.summary\"] = \" \".join(this_topic_nist_facts[\"fact\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce441aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6389c636",
   "metadata": {},
   "source": [
    "## Save Final Summaries\n",
    "\n",
    "We now have three summaries for every event except the Maryland Floods, where the ICS 209 summaries are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "375aa18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(\"gold.summaries.json.gz\", \"wb\") as out_file:\n",
    "    topics_json_str = json.dumps(topics)\n",
    "    out_file.write(topics_json_str.encode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f91c883",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
