{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8defa054",
   "metadata": {},
   "source": [
    "# De-Duplicating Run Facts\n",
    "\n",
    "In prior years, we de-duplicated using `streamID` from the CrisisFACTS data. This approach is problematic for abstractive runs, so we instead de-duplicated via BERTScore, where two facts are considered duplicates if they have a BERTScore > some threshold.\n",
    "\n",
    "We then merge these facts to produce a collapsed meta-fact set, where the text of the meta-fact as the text most similar to its neighboring facts and importance is the maximum importance across all neighboring facts.\n",
    "\n",
    "These collapsed meta-facts and their associated raw facts from each run are stored for summary generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3fa6700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import gzip\n",
    "import json\n",
    "import bert_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1601ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4d0b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "449a648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839038d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78a0cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"event-days\"\n",
    "OUTPUT_DIR = \"collapsed-event-days\"\n",
    "\n",
    "TOP_K = 20\n",
    "TOP_K_FOR_SUMMARY = 512\n",
    "\n",
    "BERT_THRESHOLD = 0.91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54392b19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7294739d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_facts(merged_df, req_id):\n",
    "    # Create all pairs\n",
    "    potential_dups = [\n",
    "        (l.Index,r.Index, l.factText, r.factText) \n",
    "        for l,r in combinations(merged_df.itertuples(), 2) \n",
    "        if l.Index != r.Index\n",
    "    ]\n",
    "\n",
    "    # Seperate left and right texts\n",
    "    left_texts = [t[2] for t in potential_dups]\n",
    "    right_texts = [t[3] for t in potential_dups]\n",
    "\n",
    "\n",
    "    # Generate the de-duplication scores\n",
    "    outscores = bert_score.score(\n",
    "        left_texts, \n",
    "        right_texts, \n",
    "        model_type=\"microsoft/deberta-xlarge-mnli\", \n",
    "        device=\"cuda:0\", \n",
    "        batch_size=32\n",
    "    )\n",
    "\n",
    "\n",
    "    # Filter duplicates by BERT_THRESHOLD\n",
    "    scored_dups = list(zip(potential_dups, outscores[2]))\n",
    "    dedup_dups = [d for d in scored_dups if d[1] >= BERT_THRESHOLD]\n",
    "    dedup_df = pd.DataFrame(\n",
    "        [list(d[0]) + [d[1]] for d in dedup_dups], \n",
    "        columns=[\"l_index\", \"r_index\", \"l_text\", \"r_text\", \"score\"]\n",
    "    )\n",
    "\n",
    "    # Create a graph of nodes based on similarity (over threshold creates an edge)\n",
    "    g = nx.Graph()\n",
    "    for n_id in merged_df.index:\n",
    "        g.add_node(n_id)\n",
    "    for tup in dedup_df[[\"l_index\", \"r_index\"]].itertuples():\n",
    "        g.add_edge(tup.l_index, tup.r_index)\n",
    "\n",
    "    # Copy, so we can delete top degree nodes\n",
    "    mod_g = g.copy()\n",
    "\n",
    "    # Keep track of nodes that have been collapsed\n",
    "    collapsed_facts = {}\n",
    "    collapsed_facts_counter = 0\n",
    "\n",
    "    # Iteratively remove the highest-degree node\n",
    "    while True:\n",
    "        degree_view = dict(mod_g.degree())\n",
    "        top_node = max(degree_view, key=degree_view.get)\n",
    "        top_node_degree = degree_view[top_node]\n",
    "\n",
    "        # if we have no neighbors, we can stop\n",
    "        if top_node_degree == 0:\n",
    "            break\n",
    "\n",
    "        # Otherwise, we want to collect all neighbors into this collapsed fact\n",
    "        neighbors = list(mod_g.neighbors(top_node))\n",
    "\n",
    "        # Create the fact ID and increment counter\n",
    "        this_collapsed_fact_id = \"%s-collapsed-%04d\" % (req_id, collapsed_facts_counter)\n",
    "        collapsed_facts_counter += 1\n",
    "\n",
    "        # Add all neighbors to this collapsed fact\n",
    "        collapsed_facts[this_collapsed_fact_id] = [top_node] + neighbors\n",
    "\n",
    "        # Remove all nodes covered by this collapsed fact\n",
    "        for neighbor_id in neighbors:\n",
    "            mod_g.remove_node(neighbor_id)\n",
    "        mod_g.remove_node(top_node)\n",
    "\n",
    "    # Now we take all remaining singletons\n",
    "    for n_id in mod_g.nodes():   \n",
    "        this_collapsed_fact_id = \"%s-collapsed-%04d\" % (req_id, collapsed_facts_counter)\n",
    "        collapsed_facts_counter += 1\n",
    "        collapsed_facts[this_collapsed_fact_id] = [n_id]\n",
    "\n",
    "\n",
    "    # Collect all collapsed facts into one set\n",
    "    collapsed_fact_set = []\n",
    "    for c_fact_id,collapsed_fact_ids in collapsed_facts.items():\n",
    "\n",
    "        rel_df = merged_df.loc[collapsed_fact_ids]\n",
    "        c_fact_text = merged_df.loc[collapsed_fact_ids[0]][\"factText\"]\n",
    "        c_fact_import = rel_df[\"importance\"].max()\n",
    "\n",
    "        collapsed_fact_set.append({\n",
    "            \"collapsed_fact_id\": c_fact_id,\n",
    "            \"fact_text\": c_fact_text,\n",
    "            \"relevant_facts\": rel_df[\"factID\"].values.tolist(),\n",
    "            \"num_relevant_facts\": rel_df.shape[0],\n",
    "            \"importance\": c_fact_import\n",
    "        })\n",
    "    print(\"Total Collapsed Facts:\", len(collapsed_facts))\n",
    "\n",
    "    # Create a dataframe, so we can sort by importance and truncate\n",
    "    collapsed_df = pd.DataFrame(collapsed_fact_set)\n",
    "    final_df = collapsed_df.sort_values(by=\"importance\", ascending=False).head(TOP_K_FOR_SUMMARY)\n",
    "    \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ba691f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42541f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "event-days\\CrisisFACTS-001-r10.json\n",
      "Total Collapsed Facts: 17\n",
      "event-days\\CrisisFACTS-001-r11.json\n",
      "Total Collapsed Facts: 16\n",
      "event-days\\CrisisFACTS-001-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-001-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-001-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-001-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-001-r7.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-001-r8.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-001-r9.json\n",
      "Total Collapsed Facts: 19\n",
      "event-days\\CrisisFACTS-002-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-002-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-002-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-002-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-002-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-002-r6.json\n",
      "Total Collapsed Facts: 6\n",
      "event-days\\CrisisFACTS-003-r10.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-003-r11.json\n",
      "Total Collapsed Facts: 2\n",
      "event-days\\CrisisFACTS-003-r5.json\n",
      "Total Collapsed Facts: 19\n",
      "event-days\\CrisisFACTS-003-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-003-r7.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-003-r8.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-003-r9.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r10.json\n",
      "Total Collapsed Facts: 12\n",
      "event-days\\CrisisFACTS-004-r11.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r12.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r13.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r14.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r15.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r16.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r17.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r18.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r19.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r20.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r21.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r22.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-004-r8.json\n",
      "Total Collapsed Facts: 5\n",
      "event-days\\CrisisFACTS-004-r9.json\n",
      "Total Collapsed Facts: 2\n",
      "event-days\\CrisisFACTS-005-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-005-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-005-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-005-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-006-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-006-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-006-r7.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-007-r13.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-007-r14.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-008-r10.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-008-r3.json\n",
      "Total Collapsed Facts: 16\n",
      "event-days\\CrisisFACTS-008-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-008-r5.json\n",
      "Total Collapsed Facts: 10\n",
      "event-days\\CrisisFACTS-008-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-008-r7.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-008-r8.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-008-r9.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-009-r0.json\n",
      "Total Collapsed Facts: 2\n",
      "event-days\\CrisisFACTS-009-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-009-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-009-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-009-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-009-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-009-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-010-r0.json\n",
      "Total Collapsed Facts: 15\n",
      "event-days\\CrisisFACTS-010-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-010-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-010-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-010-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-010-r5.json\n",
      "Total Collapsed Facts: 12\n",
      "event-days\\CrisisFACTS-011-r0.json\n",
      "Total Collapsed Facts: 14\n",
      "event-days\\CrisisFACTS-011-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-011-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-011-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-011-r4.json\n",
      "Total Collapsed Facts: 19\n",
      "event-days\\CrisisFACTS-012-r0.json\n",
      "Total Collapsed Facts: 14\n",
      "event-days\\CrisisFACTS-012-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-012-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-012-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-012-r4.json\n",
      "Total Collapsed Facts: 11\n",
      "event-days\\CrisisFACTS-013-r0.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-013-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-013-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-013-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-013-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r0.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-014-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r0.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-015-r6.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-016-r0.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-016-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-016-r2.json\n",
      "Total Collapsed Facts: 5\n",
      "event-days\\CrisisFACTS-016-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-017-r0.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-017-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-017-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-017-r3.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-017-r4.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-017-r5.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-018-r0.json\n",
      "Total Collapsed Facts: 17\n",
      "event-days\\CrisisFACTS-018-r1.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-018-r2.json\n",
      "Total Collapsed Facts: 20\n",
      "event-days\\CrisisFACTS-018-r3.json\n",
      "Total Collapsed Facts: 20\n"
     ]
    }
   ],
   "source": [
    "for f in glob.iglob(\"%s/CrisisFACTS-*.json\" % INPUT_DIR):\n",
    "    print(f)\n",
    "    req_id = f.rpartition(\"\\\\\")[-1].replace(\".json\", \"\")\n",
    "    \n",
    "    this_day_df = pd.read_json(f, orient=\"records\", lines=True)\n",
    "    this_day_top_k_dfs = [group.sort_values(by=\"importance\", ascending=False).head(TOP_K)[[\"factText\", \"factID\", \"importance\", \"runtag\"]] \\\n",
    "         for runtag,group in this_day_df.groupby(\"runtag\")]\n",
    "    \n",
    "    merged_df = pd.concat(this_day_top_k_dfs)\n",
    "    \n",
    "    final_df = collapse_facts(merged_df, req_id)\n",
    "    final_df.to_json(\"%s/Collapsed-%s.json\" % (OUTPUT_DIR, req_id), orient=\"records\")\n",
    "    #print(req_id)\n",
    "    # final_df.to_json(f\"{OUTPUT_DIR}/Collapsed-{req_id}.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b7b072",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf186f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
